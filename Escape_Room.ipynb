{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mentel1/Escape-Room-RL/blob/clement/Escape_Room.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install jdc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgiDMXGdVqSd",
        "outputId": "15308372-5b3f-40f1-91c3-33dcd88a1cc2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jdc\n",
            "  Downloading jdc-0.0.9-py2.py3-none-any.whl (2.1 kB)\n",
            "Installing collected packages: jdc\n",
            "Successfully installed jdc-0.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "386dc36257995b1270913ddfcdc1a838",
          "grade": false,
          "grade_id": "cell-917f710997077ab6",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "r3l93PPIUF-v"
      },
      "outputs": [],
      "source": [
        "import jdc\n",
        "# --\n",
        "import numpy as np\n",
        "# --\n",
        "from rl_glue import RLGlue\n",
        "# --\n",
        "from Agent import BaseAgent \n",
        "from Environment import BaseEnvironment  \n",
        "# --\n",
        "from manager import Manager\n",
        "# --\n",
        "from itertools import product\n",
        "# --\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "83300358f840fb91d5c9ef9a3e77e09c",
          "grade": false,
          "grade_id": "cell-bb3b3151b3f4f759",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "tiPfkIiuUF-w"
      },
      "source": [
        "#Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "54342eceb70d3ded536ef90b397df6a9",
          "grade": false,
          "grade_id": "cell-3b0342944fae98dd",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "NmS9lROIUF-x"
      },
      "outputs": [],
      "source": [
        "# Create empty EscapeRoomEnvironment class.\n",
        "\n",
        "class EscapeRoomEnvironment(BaseEnvironment):\n",
        "    def env_init(self, agent_info={}):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def env_start(self, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def env_step(self, reward, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def env_end(self, reward):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def env_cleanup(self, reward):\n",
        "        raise NotImplementedError\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "4583069bbb85ef2faa1824bf57693198",
          "grade": false,
          "grade_id": "cell-ace4da9bae087ba3",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "aQcr2ce8UF-y"
      },
      "source": [
        "## env_init()\n",
        "\n",
        "The first function we add to the environment is the initialization function which is called once when an environment object is created. In this function, the grid dimensions and special locations (start and goal locations and the cliff locations) are stored for easy use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "386dd420b57b9661e21454eb72f9783e",
          "grade": false,
          "grade_id": "cell-fa1aefc241323c3d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "oEEchbB9UF-z"
      },
      "outputs": [],
      "source": [
        "%%add_to EscapeRoomEnvironment\n",
        "\n",
        "def env_init(self, env_info={}):\n",
        "        \n",
        "        reward = None\n",
        "        state = None \n",
        "        termination = None\n",
        "        self.reward_state_term = (reward, state, termination)\n",
        "        \n",
        "        self.grid_h = env_info.get(\"grid_height\", 5) \n",
        "        self.grid_w = env_info.get(\"grid_width\", 5)\n",
        "        \n",
        " \n",
        "        self.start_loc = (self.grid_h-1, self.grid_w//2)\n",
        "        # Goal location is the bottom-right corner. (max x, max y).\n",
        "        self.goal_loc = (0,self.grid_w//2)\n",
        "        # The door is in the middle of the top line of the room\n",
        "        self.obstacle_loc = (self.goal_loc[0]+1,self.goal_loc[1])\n",
        "        #There is an obstacle before the door\n",
        "        self.key_loc = (self.grid_h-1,self.grid_w-1)\n",
        "        #The key is in the bottom right corner\n",
        "        self.got_key = False\n",
        "        #The player does not have the key in the beginning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "b388d1d1cccc77907f4137339943df39",
          "grade": false,
          "grade_id": "cell-dd93e8a1b24bc4cf",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "Evh6TfzzUF-1"
      },
      "source": [
        "## env_start()\n",
        "\n",
        "In env_start(), we initialize the agent location to be the start location and return the state corresponding to it as the first state for the agent to act upon. Additionally, we also set the reward and termination terms to be 0 and False respectively as they are consistent with the notion that there is no reward nor termination before the first action is even taken."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "58fed26db20dabd6fa4570b1f399a148",
          "grade": false,
          "grade_id": "cell-c71fa14686edfa0b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "J5cUtVdFUF-1"
      },
      "outputs": [],
      "source": [
        "%%add_to EscapeRoomEnvironment\n",
        "\n",
        "def env_start(self):\n",
        "    \"\"\"The first method called when the episode starts, called before the\n",
        "    agent starts.\n",
        "\n",
        "    Returns:\n",
        "        The first state from the environment.\n",
        "    \"\"\"\n",
        "    reward = 0\n",
        "    # agent_loc will hold the current location of the agent\n",
        "    self.agent_loc = self.start_loc\n",
        "    # state is the one dimensional state representation of the agent location.\n",
        "    state = (*self.agent_loc,self.got_key)\n",
        "    termination = False\n",
        "    self.reward_state_term = (reward, state, termination)\n",
        "\n",
        "    return self.reward_state_term[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "1c21e0e861d5f3220fff345e3d5e07b0",
          "grade": false,
          "grade_id": "cell-bf5f7e78e0019780",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "fCsMkayBUF-1"
      },
      "source": [
        "## *Implement* env_step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "e35e399a59401a069393c4fc781bad8c",
          "grade": false,
          "grade_id": "cell-45dfc79809d59695",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "ZCJufdYeUF-2"
      },
      "outputs": [],
      "source": [
        "%%add_to EscapeRoomEnvironment\n",
        "\n",
        "\n",
        "def env_step(self, action):\n",
        "\n",
        "    if action == 0: # UP \n",
        "        possible_next_loc = (self.agent_loc[0] - 1, self.agent_loc[1])\n",
        "    elif action == 1: # LEFT\n",
        "        possible_next_loc = (self.agent_loc[0], self.agent_loc[1] - 1)\n",
        "    elif action == 2: # DOWN\n",
        "        possible_next_loc = (self.agent_loc[0] + 1, self.agent_loc[1])\n",
        "    elif action == 3: # RIGHT\n",
        "        possible_next_loc = (self.agent_loc[0], self.agent_loc[1] + 1)\n",
        "    else: \n",
        "        raise Exception(str(action) + \" not in recognized actions [0: Up, 1: Left, 2: Down, 3: Right]!\")\n",
        "\n",
        "    reward = -1\n",
        "    terminal = False\n",
        "\n",
        "    if possible_next_loc not in self.forbidden_locs:\n",
        "      self.agent_loc = possible_next_loc\n",
        "      if self.agent_loc == self.goal_loc and self.got_key:\n",
        "        reward = 10\n",
        "        terminal = True\n",
        "      elif self.agent_loc == self.key_loc and not self.got_key:\n",
        "        self.got_key = True\n",
        "        reward = 1\n",
        "\n",
        "    \n",
        "    state = (*self.agent_loc,self.got_key)\n",
        "    self.reward_state_term = (reward, state, terminal)\n",
        "    return self.reward_state_term"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "4a499bb0871653446d6b303c2625df09",
          "grade": false,
          "grade_id": "cell-88082a3dab94c4a8",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "PivAmFqDUF-3"
      },
      "source": [
        "## env_cleanup()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "ef29fa83791e5f064a53af742f2859a2",
          "grade": false,
          "grade_id": "cell-4c235eb2667f9f0d",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "O9pnhnylUF-3"
      },
      "outputs": [],
      "source": [
        "%%add_to EscapeRoomEnvironment\n",
        "\n",
        "def env_cleanup(self):\n",
        "    \"\"\"Cleanup done after the environment ends\"\"\"\n",
        "    self.agent_loc = self.start_loc\n",
        "    self.got_key = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "180b31b525fb94442eb79f07d7097700",
          "grade": false,
          "grade_id": "cell-ff4e65eb47d735c9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "OmCUa0LbUF-3"
      },
      "source": [
        "#Agent : TD learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "d4eaa5e48e54f9c5e55149325b215d47",
          "grade": false,
          "grade_id": "cell-3abcfd06cde56935",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "OxpITYwjUF-4"
      },
      "outputs": [],
      "source": [
        "# Create empty TDAgent class.\n",
        "\n",
        "class TDAgent(BaseAgent):\n",
        "    def agent_init(self, agent_info={}):\n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def agent_start(self, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def agent_step(self, reward, state):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def agent_end(self, reward):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def agent_cleanup(self):        \n",
        "        raise NotImplementedError\n",
        "        \n",
        "    def agent_message(self, message):\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "83d69efb64983138188a2bad513622b1",
          "grade": false,
          "grade_id": "cell-edd826505e77e70a",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "WimVpxoxUF-4"
      },
      "source": [
        "## agent_init()\n",
        "\n",
        "As we did with the environment, we first initialize the agent once when a TDAgent object is created. In this function, we create a random number generator, seeded with the seed provided in the agent_info dictionary to get reproducible results. We also set the policy, discount and step size based on the agent_info dictionary. Finally, with a convention that the policy is always specified as a mapping from states to actions and so is an array of size (# States, # Actions), we initialize a values array of shape (# States,) to zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "24d451072e0b43f3ad7980887c6f5861",
          "grade": false,
          "grade_id": "cell-077135deef2f8fd9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "S4MMiKY7UF-4"
      },
      "outputs": [],
      "source": [
        "%%add_to TDAgent\n",
        "\n",
        "def agent_init(self, agent_info={}):\n",
        "\n",
        "    self.rand_generator = np.random.RandomState(agent_info.get(\"seed\"))\n",
        "\n",
        "    # Policy will be given, recall that the goal is to accurately estimate its corresponding value function. \n",
        "    self.policy = agent_info.get(\"policy\")\n",
        "    # Discount factor (gamma) to use in the updates.\n",
        "    self.discount = agent_info.get(\"discount\")\n",
        "    # The learning rate or step size parameter (alpha) to use in updates.\n",
        "    self.step_size = agent_info.get(\"step_size\")\n",
        "\n",
        "    self.values = np.zeros((self.policy.shape[0],))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "a4f9d05505f09198739674b1b330b9cd",
          "grade": false,
          "grade_id": "cell-99e8e59cd1f7a5ef",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "G-Z7Tv-oUF-4"
      },
      "source": [
        "## agent_start()\n",
        "\n",
        "In agent_start(), we choose an action based on the initial state and policy we are evaluating. We also cache the state so that we can later update its value when we perform a Temporal Difference update. Finally, we return the action chosen so that the RL loop can continue and the environment can execute this action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "8c5490c3d5fa88339b02cdf933f7f106",
          "grade": false,
          "grade_id": "cell-1b6dd05f7f49c1fc",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "t4O_YrOMUF-5"
      },
      "outputs": [],
      "source": [
        "%%add_to TDAgent\n",
        "\n",
        "def agent_start(self, state):\n",
        "\n",
        "    action = self.rand_generator.choice(range(self.policy.shape[1]), p=self.policy[state])\n",
        "    self.last_state = state\n",
        "    return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "fd9be2a7be0a8fbd3aee6b7c14f4ec37",
          "grade": false,
          "grade_id": "cell-a472a21b4a57b885",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "QMs-OtgdUF-5"
      },
      "source": [
        "## agent_step()\n",
        "\n",
        "In agent_step(), the agent must:\n",
        "\n",
        "- Perform an update to improve the value estimate of the previously visited state, and\n",
        "- Act based on the state provided by the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4c68b1daf60c5fbf3c75d4329048af15",
          "grade": false,
          "grade_id": "cell-2bec3235783127e8",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "60eJ-e_BUF-5"
      },
      "outputs": [],
      "source": [
        "%%add_to TDAgent\n",
        "\n",
        "def agent_step(self, reward, state):\n",
        "\n",
        "    target = reward + self.discount * self.values[state]\n",
        "    self.values[self.last_state] = self.values[self.last_state] + self.step_size * (target - self.values[self.last_state])\n",
        "\n",
        "    action = self.rand_generator.choice(range(self.policy.shape[1]), p=self.policy[state])\n",
        "    self.last_state = state\n",
        "\n",
        "    return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "8f516e1bdb6ca3f1a1ce385cf2c56765",
          "grade": false,
          "grade_id": "cell-f5ed31e224e22cda",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "0v713bxJUF-5"
      },
      "source": [
        "## agent_end() \n",
        "\n",
        "TD update for the case where an action leads to a terminal state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "65b123f954dd8176f089d389bc2e9735",
          "grade": false,
          "grade_id": "cell-08c5ac56c1a0a841",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "E6BEpgoTUF-5"
      },
      "outputs": [],
      "source": [
        "%%add_to TDAgent\n",
        "\n",
        "def agent_end(self, reward):\n",
        "\n",
        "    target = reward\n",
        "    self.values[self.last_state] = self.values[self.last_state] + self.step_size * (target - self.values[self.last_state])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "8e12df5724ecfa704bc67e2577c2ea34",
          "grade": false,
          "grade_id": "cell-06cbc6053aa156bc",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "xYYqwDA1UF-6"
      },
      "source": [
        "## agent_cleanup()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "540f808d320ce14b29ee7e8ddcda6ae7",
          "grade": false,
          "grade_id": "cell-c39f860970dfe3a7",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "6kWXZ22HUF-6"
      },
      "outputs": [],
      "source": [
        "%%add_to TDAgent\n",
        "\n",
        "def agent_cleanup(self):\n",
        "    self.last_state = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f62a4cb327c230937f3bc459f305e6f6",
          "grade": false,
          "grade_id": "cell-aadbaa36598224e6",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "y-L7pKolUF-6"
      },
      "source": [
        "## agent_message()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "9e222e9cc5396065dafe6e39a2052097",
          "grade": false,
          "grade_id": "cell-a440254b4f0573e2",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "_976hwJWUF-6"
      },
      "outputs": [],
      "source": [
        "%%add_to TDAgent\n",
        "\n",
        "def agent_message(self, message):\n",
        "    \"\"\"A function used to pass information from the agent to the experiment.\n",
        "    Args:\n",
        "        message: The message passed to the agent.\n",
        "    Returns:\n",
        "        The response (or answer) to the message.\n",
        "    \"\"\"\n",
        "    if message == \"get_values\":\n",
        "        return self.values\n",
        "    else:\n",
        "        raise Exception(\"TDAgent.agent_message(): Message not understood!\")"
      ]
    }
  ],
  "metadata": {
    "coursera": {
      "course_slug": "sample-based-learning-methods",
      "graded_item_id": "P4k5f",
      "launcher_item_id": "OwIbv"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Escape_Room.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}